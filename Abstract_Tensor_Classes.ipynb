{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import network2tikz\n",
    "import os\n",
    "from IPython.display import Image\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize, Bounds\n",
    "from IPython.core.display import display, HTML\n",
    "from networkx.algorithms import isomorphism\n",
    "import matplotlib.pyplot as plt\n",
    "from sage.combinat.symmetric_group_algebra import e as young_symmetrizer\n",
    "import ipywidgets as widgets\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparser(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, nu, rho, sigma, alpha, beta, kappa, theta, zeta, eta = \\\n",
    "            var('mu, nu, rho, sigma, alpha, beta, kappa, theta, zeta, eta')\n",
    "greek_variables = [mu, nu, rho, sigma, alpha, beta, kappa, theta, zeta, eta]\n",
    "extended_greek_variables = greek_variables[:]\n",
    "for i in range(1, 51):\n",
    "    for l in greek_variables:\n",
    "        globals()[str(l)+'_'+str(i)] = var(str(l)+'_'+str(i))\n",
    "        extended_greek_variables.append(globals()[str(l)+'_'+str(i)])\n",
    "add, floordiv, mul, pow, sub, truediv, add_var, mul_var = \\\n",
    "                        sorted(list(sage.symbolic.operators.arithmetic_operators), key=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "#cython: boundscheck=False, wraparound=False, nonecheck=False, cdivision=True\n",
    "from libc.math cimport sqrt\n",
    "\n",
    "# compiled version of the potential to minimise\n",
    "cpdef double energy(double[:] pos, long[:,:] adj, long n, double edge_length):\n",
    "    cdef double k\n",
    "    cdef double e\n",
    "    cdef double res\n",
    "    cdef int i\n",
    "    cdef int j\n",
    "    \n",
    "    k = 1.\n",
    "    e = 0.01\n",
    "    res = 0\n",
    "    for i in range(adj.shape[0]):\n",
    "        res += k*(sqrt((pos[adj[i][0]]-pos[adj[i][1]])**2+(pos[adj[i][0]+n]-pos[adj[i][1]+n])**2)-edge_length)**2\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            if (pos[i]-pos[j])**2+(pos[i+n]-pos[j+n])**2==0:\n",
    "                return 100\n",
    "            res += e/sqrt((pos[i]-pos[j])**2+(pos[i+n]-pos[j+n])**2)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render(G, debug=False, return_image=False, size=10, edge_length=0.4, out_widget=None, threaded=False):\n",
    "    \"\"\"\n",
    "    Build a tex file from graph G, compile it, transform it into an image and output it to a widget.\n",
    "    \"\"\"\n",
    "    if len(G)==0:\n",
    "        return\n",
    "    \n",
    "#     G = nx.disjoint_union(G, nx.MultiDiGraph()) # reset nodes name, \n",
    "    minimum_energy = 10e6\n",
    "    layout = 'spring_layout'\n",
    "    fun = lambda pos: energy(pos, np.array(list(G.edges()), dtype=int), len(G), float(edge_length))\n",
    "    bounds = Bounds(*np.array([(-1, 1)]*(len(G)*2)).T)\n",
    "    \n",
    "    x = []\n",
    "    for j in range(5):\n",
    "        res = minimize(fun=fun, x0=[np.random.random()*2-1 for i in range(len(G)*2)], bounds=bounds, options={\"maxiter\": 50})\n",
    "        y, f = res.x, res.fun\n",
    "        if f<minimum_energy:\n",
    "            x = y\n",
    "            minimum_energy = f\n",
    "        if debug:\n",
    "            print(\"Energy: \"+str(f)+\", fun eval: \"+ str(res.nfev))\n",
    "            \n",
    "    fun = lambda th: max([sin(th[0])*x[i]+cos(th[0])*x[i+len(G)] for i in range(len(G))])-\\\n",
    "                     min([sin(th[0])*x[i]+cos(th[0])*x[i+len(G)] for i in range(len(G))])\n",
    "    \n",
    "    res = minimize(fun=fun, x0=[float(0)], bounds=Bounds([-float(pi/2)], [float(pi/2)]))\n",
    "    th = res.x\n",
    "    if debug:\n",
    "        print(\"rotation :\"+str(th)+\" rad\")\n",
    "    \n",
    "    layout = {i: (float(cos(th)*x[i]-sin(th)*x[i+len(G)]), float(cos(th)*x[i+len(G)]+sin(th)*x[i])) for i in range(len(G))}\n",
    "    \n",
    "    shape_dict = {True: \"circle\", False: \"rectangle\"}\n",
    "    color_dict = {True: \"cyan\", False: \"green\"}\n",
    "    edge_color = {0: \"black\", 1: \"brown\", 2: \"blue\", 3: \"purple\", -1: \"red\"}\n",
    "    visual_style = {}\n",
    "    visual_style['vertex_shape'] = {n: shape_dict[g] for n, g in nx.get_node_attributes(G,'index').items()}\n",
    "    visual_style['vertex_color'] = {n: color_dict[g] for n, g in nx.get_node_attributes(G,'index').items()}\n",
    "\n",
    "    visual_style['layout'] = layout\n",
    "    visual_style['canvas'] = (float(size), float(size))\n",
    "\n",
    "    visual_style['edge_label'] = defaultdict(lambda: \"\")\n",
    "    for e in G.edges:\n",
    "        visual_style['edge_label'][e[:2]] += str((G.edges[e]['start_pos'], G.edges[e]['end_pos'])).replace(',', '')\n",
    "    visual_style['edge_label'] = dict(visual_style['edge_label'])\n",
    "    visual_style['edge_label_size'] = float(8)\n",
    "\n",
    "#     visual_style['node_label'] = {n: str(n)+\": \"+latex(G.nodes[n]['content']) for n in G}\n",
    "\n",
    "    visual_style['node_label'] = {n: latex(G.nodes[n]['content']) for n in G}\n",
    "    visual_style['margin'] = float(1.)\n",
    "    visual_style['edge_not_in_bg'] = False\n",
    "    visual_style['node_math_mode'] = True\n",
    "    visual_style['edge_color'] = {}\n",
    "    for e in G.edges:\n",
    "        visual_style['edge_color'][e[:2]] = edge_color[G.edges[e]['vector_space']]    \n",
    "    \n",
    "    \n",
    "    name = str(randint(1, 9999999999))\n",
    "    network2tikz.plot(G, 'tmp_'+name+'.tex', **visual_style)\n",
    "    \n",
    "    def work(args):\n",
    "        out, name = args[0], args[1]\n",
    "        try:\n",
    "            os.system(\"pdflatex -quiet tmp_\"+name+\".tex\")\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            os.system(\"pdfcrop tmp_\"+name+\".pdf tmp_\"+name+\"_bis.pdf\")\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            os.system(\"pdftoppm tmp_\"+name+\"_bis.pdf tmp_\"+name+\" -png\")\n",
    "        except:\n",
    "            pass\n",
    "        with out:\n",
    "            try:\n",
    "                display(Image(\"tmp_\"+name+\"-1.png\"))\n",
    "                sleep(1)\n",
    "            except:\n",
    "                pass\n",
    "        try:\n",
    "            os.remove(\"tmp_\"+name+\".aux\")\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            os.remove(\"tmp_\"+name+\".log\")\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            os.remove(\"tmp_\"+name+\".pdf\")\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            os.remove(\"tmp_\"+name+\"_bis.pdf\")\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            os.remove(\"tmp_\"+name+\".tex\")\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            os.remove(\"tmp_\"+name+\"-1.png\")\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    if out_widget is None:\n",
    "        out_widget = widgets.Output()\n",
    "    if threaded:\n",
    "        t = threading.Thread(target=work, args=((out_widget, name),))\n",
    "        t.start()\n",
    "    else:\n",
    "        work((out_widget, name))\n",
    "    \n",
    "    return out_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor_field:\n",
    "    def __init__(self, basic_tensors={}, sym={}, forced_in={}, forced_out={}, rules={}):\n",
    "        \"\"\"\n",
    "        Initialize the tensor field.\n",
    "        \"\"\"\n",
    "        self.basic_tensors = basic_tensors # dict of basic tensors\n",
    "        self.sym = sym # dict of symmetries\n",
    "        self.rules = rules # dict of simplification rules\n",
    "        \n",
    "        vector_spaces = set()\n",
    "        for a in basic_tensors.values():\n",
    "            for b, c in a:\n",
    "                vector_spaces.add(b)\n",
    "        self.VS = dict(zip(range(len(vector_spaces)), vector_spaces)) # dict of contraction spaces\n",
    "        self.index_VS = dict(zip(vector_spaces, range(len(vector_spaces)))) # inverse dict of contraction spaces\n",
    "        \n",
    "        self.edge_space = {} # contraction spaces in which the edge lives\n",
    "        for t in self.basic_tensors:\n",
    "            self.edge_space[t] = sum(([self.index_VS[a]]*b for a, b in self.basic_tensors[t]), [])\n",
    "\n",
    "        self.fin = {}\n",
    "        self.fout = {}\n",
    "        for t in self.basic_tensors:\n",
    "            self.fin[t]  = forced_in[t]  if t in forced_in  else []\n",
    "            self.fout[t] = forced_out[t] if t in forced_out else []\n",
    "        \n",
    "        self.number_of_indices = {} # number of indices of tensor t\n",
    "        for t in self.basic_tensors:\n",
    "            self.number_of_indices[t] = sum(nb_ind for VS, nb_ind in basic_tensors[t])\n",
    "            \n",
    "        self.rules_graph_in = {} # tensor object of rule pattern\n",
    "        self.rules_graph_out = {} # tensor object of rule result\n",
    "        self.rules_graph_to_match = {} # tensor object, modified for matching \n",
    "        self.rules_graph_to_match_line_graph = {} # dual graph of self.rules_graph_to_match\n",
    "        self.rules_tensor_content = {} # basic tensor content of tensor\n",
    "        \n",
    "        for a in self.rules:\n",
    "            self.rules_graph_to_match[a] = tensor(self, a)\n",
    "            self.rules_graph_in[a] = tensor(self, a)\n",
    "            self.rules_graph_out[a] = tensor(self, rules[a])\n",
    "            \n",
    "            # remove nodes that are external indices\n",
    "            self.rules_graph_to_match[a].graph.remove_nodes_from([n for n in self.rules_graph_to_match[a].graph.nodes if\n",
    "                                                self.rules_graph_to_match[a].graph.nodes[n]['index']])\n",
    "            self.rules_tensor_content[a] = set([self.rules_graph_in[a].graph.nodes[n]['content']\n",
    "                                                for n in self.rules_graph_in[a].graph if not self.rules_graph_in[a].graph.nodes[n]['index']])\n",
    "        ru = self.rules_graph_to_match\n",
    "        for r in ru:\n",
    "            ed = ru[r].graph.edges\n",
    "            ru2 = ru[r].graph.copy()\n",
    "            for e in list(ed):\n",
    "#                 if not self.VS[ed[e]['vector_space']][3]: # edge orientation doesn't matter\n",
    "#                     ru2.add_edge(e[1], e[0], start_pos=ed[e]['end_pos'], end_pos=ed[e]['start_pos'], vector_space=ed[e]['vector_space'])\n",
    "                ru2.add_edge(e[1], e[0], start_pos=ed[e]['end_pos'], end_pos=ed[e]['start_pos'], vector_space=ed[e]['vector_space']) # always add reverse\n",
    "            \n",
    "            for t in set([ru[r].graph.node[n]['content'] for n in ru[r].graph]):\n",
    "                ru2.add_node(t, content=\"Anchor_\"+str(t), index=False)\n",
    "            for n in ru[r].graph:\n",
    "                ru2.add_edge(n, ru[r].graph.node[n]['content'], start_pos=-1, end_pos=-1, vector_space=-1)\n",
    "#                 ru2.add_edge(ru[r].graph.node[n]['content'], n, start_pos=-1, end_pos=-1, vector_space=-1)\n",
    "                \n",
    "            ru[r].graph = ru2.copy()\n",
    "            self.rules_graph_to_match_line_graph[r] = ru[r].line_graph(ru[r].graph)\n",
    "        \n",
    "        \n",
    "        def penalty_score(r):\n",
    "            \"\"\"\n",
    "            Score for ordering rules. Is it really useful?\n",
    "            \"\"\"\n",
    "            res = 0\n",
    "            if self.rules[r]==0:\n",
    "                res -= 10\n",
    "            res += 4*len(SR(self.rules[r]))\n",
    "            res += len(self.rules_graph_in[r].graph)\n",
    "            return res\n",
    "            \n",
    "        self.sorted_rules = sorted(self.rules, key=penalty_score)\n",
    " \n",
    "        # generate all permutations based on the given symmetries\n",
    "        perms = {}\n",
    "        perms_dict = {}\n",
    "        for t in sym:\n",
    "            perms[t] = [] # possible indices permutations for tensor t, with sign change\n",
    "            indices_sym = [] # indices appearing in user tableaux\n",
    "            for tableau in sym[t]:\n",
    "                indices = reduce(union, map(set, tableau), set()) # collect all indices in this tableau\n",
    "                indices_sym = union(indices_sym, indices) # add it to the current list of indices\n",
    "            n_tot = sum(nb_ind for VS, nb_ind in basic_tensors[t]) # total number of indices of tensor t\n",
    "            sym[t] = list(sym[t]) # convert tuple of tableaux to list of tableaux\n",
    "            for i in set(range(n_tot)).difference(indices_sym):\n",
    "                sym[t].append([[i]]) # add size 1x1 tableaux for each forgotten index \n",
    "            index_tableau = {}\n",
    "            for i in set(range(n_tot)):\n",
    "                for j in range(len(sym[t])):\n",
    "                    for s2 in sym[t][j]:\n",
    "                        if i in s2:\n",
    "                            index_tableau[i] = j # records in which young tableau is the index i\n",
    "            for tableau in sym[t]:\n",
    "                indices = reduce(union, map(set, tableau), set()) # collect all indices\n",
    "                mapping = dict(zip(indices, range(1, len(indices)+1))) # records the mapping to [1, 2, 3, ...]\n",
    "                t2 = [[mapping[n] for n in t3] for t3 in tableau] # replace in sym to get standard young tableau\n",
    "#                 perms[t].append(dict(young_symmetrizer(t2))) # generate all permutation obtainable from the young tableau and sign\n",
    "                \n",
    "                ys = young_symmetrizer(t2)\n",
    "                SGA = ys.parent()\n",
    "                dict_of_perms = {}\n",
    "                # find permutations that let the symetrizer unchanged, or flip the sign\n",
    "                for perm in Permutations(SGA.n): # There must be a better way to generate \n",
    "                    if ys == SGA(perm)*ys:\n",
    "                        dict_of_perms[tuple(perm)] = 1\n",
    "                    if ys == -SGA(perm)*ys:\n",
    "                        dict_of_perms[tuple(perm)] = -1\n",
    "                perms[t].append(dict_of_perms)\n",
    "                \n",
    "            mapping = {}\n",
    "            reverse_mapping = {}\n",
    "            for i in range(len(sym[t])):\n",
    "                indices = reduce(union, map(set, sym[t][i]), set()) # collect all indices\n",
    "                mapping[i] = dict(zip(indices, range(1, len(indices)+1))) # records the mapping to [1, 2, 3, ...]\n",
    "                reverse_mapping[i] = dict(zip(range(1, len(indices)+1), indices)) # records the inverse mapping\n",
    "            perms_dict[t] = {}\n",
    "            for cp in cartesian_product_iterator(list(map(lambda x: list(x.keys()), perms[t]))): # cp is a tuple of permutations, one per tableau\n",
    "                perm = [-1]*n_tot\n",
    "                # honestly I don't remember how the next loop works, but it puts together multiple pieces of permutations in a sigle one\n",
    "                for i in range(n_tot):\n",
    "                    perm[i] = reverse_mapping[index_tableau[i]][cp[index_tableau[i]].index(mapping[index_tableau[i]][i])+1] \n",
    "                perms_dict[t][tuple(perm)] = product([perms[t][i][cp[i]] for i in range(len(perms[t]))]) # records the perumtation, as well as the sign associated (1 or -1)\n",
    "        self.index_permutations = perms_dict\n",
    "        \n",
    "    def sign_permutation(self, permutation, t):\n",
    "        \"\"\"\n",
    "        Given a complete permutation of indices in dictionnary format, how does it affect the tensor t ?\n",
    "        - it is equal to t:           return p, 1\n",
    "        - it is equal to -t:          return p, -1\n",
    "        - it does something else:     return p, 0\n",
    "\n",
    "        The permutation can contain holes. In this case the function returns a matching\n",
    "        (complete permutation, sign) if found, (incomplete permutation, 0) otherwise.\n",
    "        incomplete permutation contains -1 in place of missing numbers.\n",
    "        \"\"\"\n",
    "        \n",
    "        if t not in basic_tensors:\n",
    "            return (0,), 1\n",
    "        \n",
    "        p = [-1]*sum(nb_ind for VS, nb_ind in basic_tensors[t])\n",
    "        for i in permutation:\n",
    "            p[i] = permutation[i]\n",
    "        p = tuple(p)\n",
    "        \n",
    "        perms = self.index_permutations[t]\n",
    "\n",
    "        if p in perms:\n",
    "            return p, perms[p]\n",
    "\n",
    "        for candidate in perms:\n",
    "            if all([p[i]==candidate[i] or p[i]==-1 for i in range(len(p))]):\n",
    "                return candidate, perms[candidate]\n",
    "\n",
    "        return p, 0\n",
    "    \n",
    "    def simplify(self, expr):\n",
    "        \"\"\"\n",
    "        Simplify an expression containing tensors.\n",
    "        \"\"\"\n",
    "        T = tensor(self, expr)\n",
    "        T.simplify()\n",
    "        return T.to_expression()\n",
    "    \n",
    "    def __call__(self, expr):\n",
    "        return tensor(self, expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tensor:\n",
    "    def __init__(self, TF, E=1, graph=None):\n",
    "        \"\"\"\n",
    "        Create a tensor from a symbolic expression or a graph. You should never call this directly.\n",
    "        \"\"\"\n",
    "        if graph is not None:\n",
    "            self.TF = TF\n",
    "            self.operator = mul_var\n",
    "            self.ext_ind = graph.graph['indices']\n",
    "            self.prefactor = graph.graph['prefactor']\n",
    "            self.leaf = True\n",
    "            self.is_scalar = len(graph)==0\n",
    "            self.operands = [1]\n",
    "            self.graph = graph.copy()\n",
    "            self.E = 1\n",
    "            self.fully_simplified = False\n",
    "            return\n",
    "        \n",
    "        E = SR(E).expand()\n",
    "        self.TF = TF\n",
    "        self.operator = E.operator()\n",
    "        self.ext_ind = []\n",
    "        \n",
    "        if self.operator in self.TF.basic_tensors:\n",
    "            self.prefactor = 1\n",
    "            self.E = E\n",
    "            self.leaf = True\n",
    "            self.is_scalar = False\n",
    "            self.operands = [E]\n",
    "            \n",
    "        elif self.operator is add_var:\n",
    "            self.prefactor = 1\n",
    "            self.E = E\n",
    "            self.leaf = False\n",
    "            self.operands = [tensor(TF, op) for op in E.operands()]\n",
    "            self.is_scalar = all([t.is_scalar for t in self.operands])\n",
    "        \n",
    "        elif self.operator is pow and E.operands()[1]==2:\n",
    "            op = [E.operands()[0], E.operands()[0]]\n",
    "            self.E = 1\n",
    "            self.prefactor = 1\n",
    "            for op2 in op:\n",
    "                if op2.operator() in self.TF.basic_tensors:\n",
    "                    self.E *= op2\n",
    "                else:\n",
    "                    self.prefactor *= op2\n",
    "            self.leaf = True\n",
    "            self.is_scalar = self.E.is_trivially_equal(SR(1))\n",
    "            self.operator = mul_var\n",
    "            self.operands = op\n",
    "\n",
    "        elif self.operator is mul_var:\n",
    "            op = E.operands()\n",
    "            self.E = 1\n",
    "            self.prefactor = 1\n",
    "            self.operands = []\n",
    "            for op2 in op:\n",
    "                if op2.operator() in self.TF.basic_tensors:\n",
    "                    self.E *= op2\n",
    "                    self.operands += [op2]\n",
    "                elif op2.operator() is pow and op2.operands()[1]==2:\n",
    "                    op3 = op2.operands()[0]\n",
    "                    if op3.operator() in self.TF.basic_tensors:\n",
    "                        self.E *= op3\n",
    "                        self.E *= op3\n",
    "                        self.operands += [op3, op3]\n",
    "                else:\n",
    "                    self.prefactor *= op2\n",
    "            self.leaf = True\n",
    "            self.is_scalar = self.E.is_trivially_equal(SR(1))\n",
    "            self.operator = mul_var\n",
    "\n",
    "        else:\n",
    "            self.leaf = True\n",
    "            self.is_scalar = True\n",
    "            self.E = 1\n",
    "            self.prefactor = E\n",
    "            self.operands = [1]\n",
    "\n",
    "        self.fully_simplified = False\n",
    "        \n",
    "        self.generate_graph()\n",
    "        \n",
    "    def _latex_(self):\n",
    "        \"\"\"\n",
    "        Return a latex representation of the tensor.\n",
    "        \"\"\"\n",
    "        return SR(self.to_expression())._latex_()\n",
    "    \n",
    "    def expand(self):\n",
    "        \"\"\"\n",
    "        Expand the tensor, only useful for sum of sum.\n",
    "        \"\"\"\n",
    "        if self.operator is add_var:\n",
    "            for op in self.operands:\n",
    "                op.expand()\n",
    "            new_op = []\n",
    "            for i in range(len(self.operands)):\n",
    "                op = self.operands[i]\n",
    "                op2 = op.operator\n",
    "                if op2 is add_var:\n",
    "                    new_op += op.__copy__().operands\n",
    "                else:\n",
    "                    new_op.append(op.__copy__())\n",
    "            self.operands = new_op\n",
    "        \n",
    "    def plot(self, debug=False, size=10, edge_length=0.2, threaded=False):\n",
    "        \"\"\"\n",
    "        Display the tensor in graphical notation.\n",
    "        \"\"\"\n",
    "        if self.leaf:\n",
    "            return render(self.graph, debug=debug, return_image=False, size=size, edge_length=edge_length, threaded=threaded)\n",
    "        else:\n",
    "            out_widget = widgets.Output()\n",
    "            for op in self.operands:\n",
    "                render(op.graph, debug=debug, return_image=False, size=size, edge_length=edge_length, out_widget=out_widget, threaded=threaded)\n",
    "            return out_widget\n",
    "    \n",
    "    def graph_leaf(self):\n",
    "        \"\"\"\n",
    "        Transform a leaf of the symbolic expression into a graph.\n",
    "        \"\"\"\n",
    "        if self.is_scalar:\n",
    "            self.graph = nx.MultiDiGraph(prefactor=self.prefactor, indices=[])\n",
    "            return\n",
    "        \n",
    "        if self.operator in self.TF.basic_tensors:\n",
    "            res = nx.MultiDiGraph(prefactor=self.prefactor, indices=[])\n",
    "            res.add_node(int(0), content=self.operator, index=False)\n",
    "            op = self.E.operands()\n",
    "            done = [False]*len(op)\n",
    "            for i in range(len(op)):\n",
    "                if not done[i]:\n",
    "                    for j in range(i+1, len(op)):\n",
    "                        if not done[j]:\n",
    "                            if op[i]==op[j]:\n",
    "                                done[i] = True\n",
    "                                done[j] = True\n",
    "                                if self.TF.edge_space[self.operator][i]!=self.TF.edge_space[self.operator][j]:\n",
    "                                    raise Exception(\"Incompatible index spaces: \"+\n",
    "                                                        str(self.TF.VS[self.TF.edge_space[self.operator][i]])+\" and \"+\n",
    "                                                        str(self.TF.VS[self.TF.edge_space[self.operator][j]]))\n",
    "                                inversion = False\n",
    "                                if j in self.TF.fout[self.operator] or i in self.TF.fin[self.operator]:\n",
    "                                    i, j = j, i\n",
    "                                    inversion = True\n",
    "                                if j in self.TF.fout[self.operator] or i in self.TF.fin[self.operator]:\n",
    "                                    raise Exception(\"Impossible contraction: \"+str(op[i]))\n",
    "\n",
    "                                res.add_edge(0, 0, start_pos=i, end_pos=j,\n",
    "                                             vector_space=self.TF.edge_space[self.operator][i])\n",
    "                                if inversion:\n",
    "                                    i, j = j, i\n",
    "\n",
    "                                break\n",
    "                    else:\n",
    "                        res.add_node(len(res), content=op[i], index=True)\n",
    "                        if i in self.TF.fout[self.operator]:\n",
    "                            res.add_edge(0, len(res)-1, start_pos=i, end_pos=0,\n",
    "                                         vector_space=self.TF.edge_space[self.operator][i])\n",
    "                        else:\n",
    "                            res.add_edge(len(res)-1, 0, start_pos=0, end_pos=i,\n",
    "                                         vector_space=self.TF.edge_space[self.operator][i])\n",
    "                        res.graph['indices'] += [op[i]]\n",
    "            self.graph = res\n",
    "            return\n",
    "        \n",
    "        op = self.operands\n",
    "        if self.operator is pow and op[1]==2:\n",
    "            op = [op[0], op[0]]\n",
    "            self.operator = mul_var\n",
    "        \n",
    "        if self.operator is not mul_var:\n",
    "            raise Exception(\"Error, expected mul_var\")\n",
    "        \n",
    "        \n",
    "        indices = [op2.operands() for op2 in op]\n",
    "        done = [[False]*len(op2.operands()) for op2 in op]\n",
    "        res = nx.MultiDiGraph(prefactor=self.prefactor, indices=[])\n",
    "        for i in range(len(op)):\n",
    "            res.add_node(i, content=op[i].operator(), index=False)\n",
    "        for i in range(len(op)):\n",
    "            for k in range(len(indices[i])):\n",
    "                if not done[i][k]:\n",
    "                    found = False\n",
    "                    for j in range(i+1, len(op)):\n",
    "                        for l in range(len(indices[j])):\n",
    "                            if not done[j][l] and not done[i][k]:\n",
    "                                if str(indices[i][k]) == str(indices[j][l]): #PB ????\n",
    "                                    if self.TF.edge_space[op[i].operator()][k]!=self.TF.edge_space[op[j].operator()][l]:\n",
    "                                        raise Exception(\"Incompatible index spaces: \"+\n",
    "                                                        str(self.TF.VS[self.TF.edge_space[op[i].operator()][k]])+\" and \"+\n",
    "                                                        str(self.TF.VS[self.TF.edge_space[op[j].operator()][l]]))\n",
    "                                    inversion = False\n",
    "                                    if l in self.TF.fout[op[j].operator()] or k in self.TF.fin[op[i].operator()]:\n",
    "                                        i, j, k, l = j, i, l, k\n",
    "                                        inversion = True\n",
    "                                    if l in self.TF.fout[op[j].operator()] or k in self.TF.fin[op[i].operator()]:\n",
    "                                        raise Exception(\"Impossible contraction: \"+str(indices[i][k]))\n",
    "\n",
    "                                    res.add_edge(i, j, start_pos=k, end_pos=l, \n",
    "                                                 vector_space=self.TF.edge_space[op[i].operator()][k])\n",
    "                                    if inversion:\n",
    "                                        i, j, k, l = j, i, l, k\n",
    "                                    found = True\n",
    "                                    done[i][k] = True\n",
    "                                    done[j][l] = True\n",
    "                    for l in range(k+1, len(indices[i])):\n",
    "                        if not done[i][l] and not done[i][k]:\n",
    "                            if indices[i][k]==indices[i][l]:\n",
    "                                if self.TF.edge_space[op[i].operator()][k]!=self.TF.edge_space[op[i].operator()][l]:\n",
    "                                        raise Exception(\"Incompatible index spaces: \"+\n",
    "                                                        str(self.TF.VS[self.TF.edge_space[op[i].operator()][k]])+\" and \"+\n",
    "                                                        str(self.TF.VS[self.TF.edge_space[op[i].operator()][l]]))\n",
    "                                inversion = False\n",
    "                                if l in self.TF.fout[op[i].operator()] or k in self.TF.fin[op[i].operator()]:\n",
    "                                    k, l = l, k\n",
    "                                    inversion = True\n",
    "                                if l in self.TF.fout[op[i].operator()] or k in self.TF.fin[op[i].operator()]:\n",
    "                                    raise Exception(\"Impossible contraction: \"+str(indices[i][k]))\n",
    "\n",
    "                                res.add_edge(i, i, start_pos=k, end_pos=l,\n",
    "                                             vector_space=self.TF.edge_space[op[i].operator()][k])\n",
    "                                if inversion:\n",
    "                                    k, l = l, k\n",
    "                                found = True\n",
    "                                done[i][k] = True\n",
    "                                done[i][l] = True\n",
    "                    if not found:\n",
    "                        res.add_node(len(res), content=indices[i][k], index=True)\n",
    "                        if k in self.TF.fout[op[i].operator()]:\n",
    "                            res.add_edge(i, len(res)-1, start_pos=k, end_pos=0,\n",
    "                                         vector_space=self.TF.edge_space[op[i].operator()][k])\n",
    "                        else:\n",
    "                            res.add_edge(len(res)-1, i, start_pos=0, end_pos=k,\n",
    "                                         vector_space=self.TF.edge_space[op[i].operator()][k])\n",
    "                        res.graph['indices'] += [indices[i][k]]\n",
    "        self.graph = res\n",
    "        return\n",
    "    \n",
    "    def generate_graph(self):\n",
    "        \"\"\"\n",
    "        Transform a symbolic expression into a graph, or sum of tensor.\n",
    "        \"\"\"\n",
    "        if self.operator is not add_var:\n",
    "            self.graph_leaf()\n",
    "            return\n",
    "        for op in self.operands:\n",
    "            op.graph_leaf()\n",
    "        self.graph = nx.MultiDiGraph(prefactor=1, indices=[])\n",
    "    \n",
    "    def line_graph(self, G):\n",
    "        \"\"\"\n",
    "        Return the dual graph of G, and propagate the attibutes.\n",
    "        \"\"\"\n",
    "        G2 = nx.line_graph(G)\n",
    "        nx.set_edge_attributes(G2, {(n1, n2, key): G.nodes[n1[1]] for n1, n2, key in G2.edges})\n",
    "        nx.set_node_attributes(G2, {(n1, n2, key): G.edges[n1, n2, key] for n1, n2, key in G2.nodes})\n",
    "        for n1, n2, key in G2.nodes:\n",
    "            G2.nodes[n1, n2, key]['start_content'] = G.node[n1]['content']\n",
    "            G2.nodes[n1, n2, key]['end_content']   = G.node[n2]['content']\n",
    "        return G2\n",
    "\n",
    "    def share_a_symmetry(self, e1, e2, tensor):\n",
    "        \"\"\"\n",
    "        return True if e1 and e2 appears in the same Young tableau for the specified tensor.\n",
    "        \"\"\"\n",
    "        if e1==e2:\n",
    "            return True\n",
    "        if tensor not in self.TF.sym:\n",
    "            return False\n",
    "        for tableau in self.TF.sym[tensor]:\n",
    "            found_e1 = False\n",
    "            found_e2 = False\n",
    "            for line in tableau:\n",
    "                if e1 in line:\n",
    "                    found_e1 = True\n",
    "                if e2 in line:\n",
    "                    found_e2 = True\n",
    "            if found_e1 and found_e2:\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def find_step(self):\n",
    "        \"\"\"\n",
    "        Find a rule that can be applied to self by looking for isomorphic subgraph in the dual graph of self.\n",
    "        \"\"\"     \n",
    "        \n",
    "        # node comparison function\n",
    "        def test_edge(e1, e2):\n",
    "            return bool(e1[0]['content'] is e2[0]['content'])\n",
    "        \n",
    "        # fast edge comparison function: can accept a false result, mappings need to be checked afterward.\n",
    "        def test_node(n1, n2):\n",
    "            if (n1['start_pos']==-1 and n2['start_pos']==-1):\n",
    "                return n1['end_content']==n2['end_content']\n",
    "            return (n1['start_pos']==n2['start_pos'] and n1['end_pos']==n2['end_pos']) or \\\n",
    "                        (self.share_a_symmetry(n1['start_pos'], n2['start_pos'], n1['start_content']) and \n",
    "                         self.share_a_symmetry(n1['end_pos'], n2['end_pos'], n1['end_content'])) # ensures edges are of the same type\n",
    "\n",
    "        ed = self.graph.edges\n",
    "        G2 = self.graph.copy()\n",
    "        for e in list(ed):\n",
    "            G2.add_edge(e[1], e[0], start_pos=ed[e]['end_pos'], end_pos=ed[e]['start_pos'], vector_space=ed[e]['vector_space']) # always add reverse\n",
    "        for t in set([G2.node[n]['content'] for n in G2]):\n",
    "            G2.add_node(t, content=\"Anchor_\"+str(t), index=False)\n",
    "        for n in G2:\n",
    "            if type(n) is int:\n",
    "                G2.add_edge(n, G2.node[n]['content'], start_pos=-1, end_pos=-1, vector_space=-1)\n",
    "                G2.add_edge(G2.node[n]['content'], n, start_pos=-1, end_pos=-1, vector_space=-1)\n",
    "        LG2 = self.line_graph(G2)\n",
    "        \n",
    "        rules = self.TF.rules_graph_in\n",
    "        for r in self.TF.sorted_rules:\n",
    "            \n",
    "            # for each rule, look for a mapping\n",
    "            \n",
    "            if not set([self.graph.nodes[n]['content'] for n in self.graph if not self.graph.nodes[n]['index']]).issuperset(self.TF.rules_tensor_content[r]):\n",
    "                continue\n",
    "            \n",
    "            LG1 = self.TF.rules_graph_to_match_line_graph[r]\n",
    "            GM = isomorphism.DiGraphMatcher(LG2, LG1, edge_match=test_edge, node_match=test_node)\n",
    "            for mapping in GM.subgraph_isomorphisms_iter():\n",
    "                \n",
    "                # a mapping candidate was found\n",
    "                # do we accept it or not ?\n",
    "                \n",
    "                edge_map = mapping\n",
    "                node_map = {}\n",
    "                for a in edge_map:\n",
    "                    if type(a[0]) is int:\n",
    "                        node_map[a[0]] = edge_map[a][0]\n",
    "                    if type(a[1]) is int:\n",
    "                        node_map[a[1]] = edge_map[a][1]\n",
    "                        \n",
    "                edge_map_2 = {}        \n",
    "                for e in edge_map: # recover forced ordering\n",
    "                    if G2.edges[e]['start_pos']!=-1:\n",
    "                        if G2.edges[e]['end_pos'] in self.TF.fin[G2.nodes[e[1]]['content']] and G2.edges[e]['start_pos'] in self.TF.fout[G2.nodes[e[0]]['content']]:\n",
    "                            edge_map_2[e] = edge_map[e]\n",
    "                        elif G2.edges[e]['start_pos'] in self.TF.fin[G2.nodes[e[0]]['content']] and G2.edges[e]['end_pos'] in self.TF.fout[G2.nodes[e[1]]['content']]:\n",
    "                            edge_map_2[e[1], e[0], 0] = edge_map[e][1], edge_map[e][0], 0\n",
    "                        else:\n",
    "                            if e[2]==0: # self loops can cause trouble if not here ???\n",
    "                                edge_map_2[e] = edge_map[e]\n",
    "                            \n",
    "\n",
    "                edge_map = edge_map_2\n",
    "\n",
    "                edge_map_2 = {}\n",
    "                for e in edge_map:\n",
    "                    if all([type(i) is int for i in e]):\n",
    "                        if not e in self.graph.edges:\n",
    "                            edge_map_2[e[1], e[0], e[2]] = edge_map[e]\n",
    "                        else:\n",
    "                            edge_map_2[e] = edge_map[e]\n",
    "                \n",
    "                accept = True\n",
    "\n",
    "                for n in node_map:\n",
    "                    perm = {}\n",
    "                    for e in edge_map_2:\n",
    "                        if n==e[0]:\n",
    "                            perm[self.graph.edges[e]['start_pos']] = self.TF.rules_graph_to_match[r].graph.edges[edge_map_2[e]]['start_pos']\n",
    "                        if n==e[1]:\n",
    "                            perm[self.graph.edges[e]['end_pos']] = self.TF.rules_graph_to_match[r].graph.edges[edge_map_2[e]]['end_pos']\n",
    "                    p, s = self.TF.sign_permutation(perm, self.graph.nodes[n]['content'])\n",
    "                    \n",
    "                    if s==0:\n",
    "                        accept = False # symmetry is not a factor of 1 or -1\n",
    "                        \n",
    "                if accept:\n",
    "                    return r, edge_map, node_map # mapping is a real subgraph isomorphism, interrupt the search\n",
    "\n",
    "        return False, False, False\n",
    "    \n",
    "    def normalize_graph(self):\n",
    "        \"\"\"\n",
    "        Rename the nodes of the graph so that the indices are at the end.\n",
    "        \"\"\"\n",
    "        relabel = {}\n",
    "        for n in self.graph.nodes:\n",
    "            if self.graph.nodes[n]['index']:\n",
    "                relabel[n] = n+len(self.graph)\n",
    "            else:\n",
    "                relabel[n] = n\n",
    "        nx.relabel_nodes(self.graph, relabel, copy=False)\n",
    "        self.graph = nx.relabel.convert_node_labels_to_integers(self.graph, first_label=0, ordering=\"sorted\")\n",
    "    \n",
    "    def simplify_metric(self):\n",
    "        \"\"\"\n",
    "        Simplify identity.\n",
    "        \"\"\"\n",
    "        for n in self.graph.nodes:\n",
    "            for vs in self.TF.VS:\n",
    "                if self.TF.VS[vs][2] is self.graph.nodes[n]['content']:\n",
    "                    a = list(self.graph.in_edges(n)) # incoming\n",
    "                    b = list(self.graph.out_edges(n)) # outgoing\n",
    "\n",
    "                    if len(a)==2:\n",
    "                        if not (self.graph.nodes[a[0][0]]['index'] and self.graph.nodes[a[1][0]]['index']):\n",
    "                            if not (a[0][0], a[0][1], 1) in self.graph.edges: # 2 different incoming edges\n",
    "                                pos = self.graph.edges[a[0][0], a[0][1], 0]['start_pos'], self.graph.edges[a[1][0], a[1][1], 0]['start_pos']\n",
    "                                self.graph.remove_node(n)\n",
    "                                self.graph.add_edge(a[0][0], a[1][0], start_pos=pos[0], end_pos=pos[1], vector_space=vs)\n",
    "                                self.normalize_graph()\n",
    "                                return True\n",
    "                            else: # 2 incoming edges from one same node\n",
    "                                pos = self.graph.edges[a[0][0], a[0][1], 0]['start_pos'], self.graph.edges[a[0][0], a[0][1], 1]['start_pos']\n",
    "                                self.graph.remove_node(n)\n",
    "                                self.graph.add_edge(a[0][0], a[1][0], start_pos=pos[0], end_pos=pos[1], vector_space=vs)\n",
    "                                self.normalize_graph()\n",
    "                                return True                \n",
    "\n",
    "                    if len(b)==2:\n",
    "                        if not (self.graph.nodes[b[0][1]]['index'] and self.graph.nodes[b[1][1]]['index']):\n",
    "                            if not (b[0][0], b[0][1], 1) in self.graph.edges: # 2 different outgoing edges\n",
    "                                pos = self.graph.edges[b[0][0], b[0][1], 0]['end_pos'], self.graph.edges[b[1][0], b[1][1], 0]['end_pos']\n",
    "                                self.graph.remove_node(n)\n",
    "                                self.graph.add_edge(b[0][1], b[1][1], start_pos=pos[0], end_pos=pos[1], vector_space=vs)\n",
    "                                self.normalize_graph()\n",
    "                                return True\n",
    "\n",
    "                            else: # 2 outgoing edges from the same node\n",
    "                                pos = self.graph.edges[b[0][0], b[0][1], 0]['end_pos'], self.graph.edges[b[0][0], b[0][1], 1]['end_pos']\n",
    "                                self.graph.remove_node(n)\n",
    "                                self.graph.add_edge(b[0][1], b[1][1], start_pos=pos[0], end_pos=pos[1], vector_space=vs)\n",
    "                                self.normalize_graph()\n",
    "                                return True\n",
    "\n",
    "                    if len(a)==1 and len(b)==1:\n",
    "                        if a[0][0]==a[0][1]: # isolated self loop\n",
    "                            self.graph.remove_node(n)\n",
    "                            self.graph.graph['prefactor'] = self.graph.graph['prefactor']*self.TF.VS[vs][1] # trace(g) = dim(E)\n",
    "                            self.normalize_graph()\n",
    "                            return True\n",
    "\n",
    "                        # one incoming and one outgoing edge: must preserve orientation\n",
    "                        if not (self.graph.nodes[b[0][1]]['index'] and self.graph.nodes[a[0][0]]['index']):\n",
    "                            pos = self.graph.edges[a[0][0], a[0][1], 0]['start_pos'], self.graph.edges[b[0][0], b[0][1], 0]['end_pos'], self.graph.nodes[n]['content']\n",
    "                            self.graph.remove_node(n)\n",
    "                            self.graph.add_edge(a[0][0], b[0][1], start_pos=pos[0], end_pos=pos[1], vector_space=vs)\n",
    "                            self.normalize_graph()\n",
    "                            return True\n",
    "        return False\n",
    "\n",
    "    \n",
    "    def match_step(self):\n",
    "        \"\"\"\n",
    "        Find a rule to apply, then replace the pattern with the corresponding result.\n",
    "        This is graph surgery, no pun intended.\n",
    "        \n",
    "        Return True if something was changes, False otherwise.\n",
    "        \"\"\"\n",
    "        while self.simplify_metric():\n",
    "            pass\n",
    "        \n",
    "        rule, edge_map, node_map = self.find_step()\n",
    "        \n",
    "        if rule is False:\n",
    "            return False\n",
    "        \n",
    "        edge_map_2 = {}\n",
    "        for e in edge_map:\n",
    "            if not e in self.graph.edges:\n",
    "                edge_map_2[e[1], e[0], e[2]] = edge_map[e]\n",
    "            else:\n",
    "                edge_map_2[e] = edge_map[e]\n",
    "\n",
    "        sign = []\n",
    "        index_permutation = {}\n",
    "        for n in node_map:\n",
    "            perm = {}\n",
    "            for e in edge_map_2:\n",
    "                if n==e[0]:\n",
    "                    perm[self.graph.edges[e]['start_pos']] = self.TF.rules_graph_to_match[rule].graph.edges[edge_map_2[e]]['start_pos']\n",
    "                if n==e[1]:\n",
    "                    perm[self.graph.edges[e]['end_pos']] = self.TF.rules_graph_to_match[rule].graph.edges[edge_map_2[e]]['end_pos']\n",
    "            p, s = self.TF.sign_permutation(perm, self.graph.nodes[n]['content'])\n",
    "            sign += [s]\n",
    "            index_permutation[n] = p\n",
    "        sign = product(sign)\n",
    "\n",
    "        \n",
    "        inverse_node_map = {v: k for k, v in node_map.items()}\n",
    "        \n",
    "        external_leg_in = {} # where on the pattern (to match) does the leg connect\n",
    "        external_leg_out = {}\n",
    "        G = self.TF.rules_graph_in[rule].graph\n",
    "        for n in G.nodes:\n",
    "            if(G.nodes[n]['index']):\n",
    "                for _, a in G.out_edges(n):\n",
    "                    external_leg_in[G.nodes[n]['content']] = (a, G.edges[(n, a, 0)]['end_pos']) # (node, pos)\n",
    "                for a, _ in G.in_edges(n):\n",
    "                    external_leg_out[G.nodes[n]['content']] = (a, G.edges[(a, n, 0)]['start_pos'])\n",
    "        \n",
    "        external_map_in = {} # IN according to the rules, NOT the graph, where does the leg connect on the outside world in T\n",
    "        for index in external_leg_in:\n",
    "            for a, b in self.graph.in_edges(inverse_node_map[external_leg_in[index][0]]): \n",
    "                for i in range(self.TF.number_of_indices[self.graph.nodes[inverse_node_map[external_leg_in[index][0]]]['content']]):\n",
    "                    if (a, b, i) in self.graph.edges and self.graph.edges[a, b, i]['end_pos']==external_leg_in[index][1]:\n",
    "                        external_map_in[index] = (a, self.graph.edges[a, b, i]['start_pos']) # (node, po)\n",
    "            for b, a in self.graph.out_edges(inverse_node_map[external_leg_in[index][0]]): # case where arrow is reversed\n",
    "                for i in range(self.TF.number_of_indices[self.graph.nodes[inverse_node_map[external_leg_in[index][0]]]['content']]):\n",
    "                    if (b, a, i) in self.graph.edges and self.graph.edges[b, a, i]['start_pos']==external_leg_in[index][1]:\n",
    "                        external_map_in[index] = (a, self.graph.edges[b, a, i]['end_pos'])\n",
    "        external_map_out = {} # OUT according to the rules, NOT the graph\n",
    "        for index in external_leg_out:\n",
    "            for a, b in self.graph.in_edges(inverse_node_map[external_leg_out[index][0]]): # case where arrow is reversed\n",
    "                for i in range(self.TF.number_of_indices[self.graph.nodes[inverse_node_map[external_leg_out[index][0]]]['content']]):\n",
    "                    if (a, b, i) in self.graph.edges and self.graph.edges[a, b, i]['end_pos']==external_leg_out[index][1]:\n",
    "                        external_map_out[index] = (a, self.graph.edges[a, b, i]['start_pos']) # (node, po)\n",
    "            for b, a in self.graph.out_edges(inverse_node_map[external_leg_out[index][0]]): \n",
    "                for i in range(self.TF.number_of_indices[self.graph.nodes[inverse_node_map[external_leg_out[index][0]]]['content']]):\n",
    "                    if (b, a, i) in self.graph.edges and self.graph.edges[b, a, i]['start_pos']==external_leg_out[index][1]:\n",
    "                        external_map_out[index] = (a, self.graph.edges[b, a, i]['end_pos'])\n",
    "        \n",
    "        self.graph.remove_nodes_from(node_map)\n",
    "        \n",
    "        shift = len(self.graph)\n",
    "                \n",
    "        \n",
    "        list_of_replacement = []\n",
    "        \n",
    "        \n",
    "        if self.TF.rules_graph_out[rule].operator is add_var:  \n",
    "            for op in self.TF.rules_graph_out[rule].operands:\n",
    "                list_of_replacement.append(op.graph.copy())\n",
    "             \n",
    "        else:\n",
    "            if self.TF.rules_graph_out[rule].prefactor==0: # zero, returning now\n",
    "                self.graph = nx.MultiDiGraph(prefactor=0)\n",
    "                self.prefactor = 0\n",
    "                return True            \n",
    "            \n",
    "            G2 = self.TF.rules_graph_out[rule].graph.copy()\n",
    "            list_of_replacement.append(G2)\n",
    "        \n",
    "        \n",
    "        resulting_tensor = []\n",
    "        for G2 in list_of_replacement: # START LOOP -------------------------------------------------------------------------------------------------------\n",
    "            \n",
    "            pref = G2.graph['prefactor']*sign*self.graph.graph['prefactor']\n",
    "            \n",
    "            external_leg_replace_in = {} # where does the replacing pattern connect to the tensor ?\n",
    "            external_leg_replace_out = {}\n",
    "            for n in G2.nodes:\n",
    "                if(G2.nodes[n]['index']):\n",
    "                    for _, a in G2.out_edges(n):\n",
    "                        external_leg_replace_in[G2.nodes[n]['content']] = (a, G2.edges[(n, a, 0)]['end_pos']) # (node, pos)\n",
    "                    for a, _ in G2.in_edges(n):\n",
    "                        external_leg_replace_out[G2.nodes[n]['content']] = (a, G2.edges[(a, n, 0)]['start_pos'])\n",
    "\n",
    "            G2.remove_nodes_from([n for n in G2.nodes if G2.nodes[n]['index']])\n",
    "            \n",
    "            \n",
    "            temp_graph = self.graph.copy()\n",
    "            old_order = list(temp_graph.nodes)\n",
    "            temp_graph = nx.relabel.convert_node_labels_to_integers(temp_graph, first_label=0, ordering=\"sorted\")\n",
    "            new_order = list(temp_graph.nodes)\n",
    "            relabel_mapping = dict(zip(old_order, new_order))\n",
    "\n",
    "            relabel = {}\n",
    "            for n in G2.nodes:\n",
    "                relabel[n] = n+shift\n",
    "            G2 = nx.relabel_nodes(G2, relabel)\n",
    "            \n",
    "#             print(self)\n",
    "#             print(temp_graph.nodes, G2.nodes, shift)\n",
    "            temp_graph = nx.union(temp_graph, G2) # the right thing to do\n",
    "\n",
    "            G3 = temp_graph\n",
    "\n",
    "            internal_mapping = set()\n",
    "            external_map_in2 = {}\n",
    "            external_map_out2 = {}\n",
    "            for ind, (a, b) in external_map_in.items():\n",
    "                if a in relabel_mapping:\n",
    "                    external_map_in2[ind] = relabel_mapping[a], b\n",
    "                else:\n",
    "                    for other_ind, (a2, b2) in external_leg_in.items():\n",
    "                        if other_ind is not ind:\n",
    "                            if inverse_node_map[a2]==a and external_map_in[other_ind][0]==inverse_node_map[external_leg_in[ind][0]]:\n",
    "                                if (other_ind, ind) not in internal_mapping:\n",
    "                                    internal_mapping.add((ind, other_ind)) # arbitrary ordering\n",
    "\n",
    "                    for other_ind, (a2, b2) in external_leg_out.items():\n",
    "                        if other_ind is not ind:\n",
    "                            if inverse_node_map[a2]==a and external_map_out[other_ind][0]==inverse_node_map[external_leg_in[ind][0]]:\n",
    "                                if (other_ind, ind) not in internal_mapping:\n",
    "                                    internal_mapping.add((ind, other_ind)) # ordering ???\n",
    "            for ind, (a, b) in external_map_out.items():\n",
    "                if a in relabel_mapping:\n",
    "                    external_map_out2[ind] = relabel_mapping[a], b\n",
    "                else:\n",
    "                    for other_ind, (a2, b2) in external_leg_out.items():\n",
    "                        if other_ind is not ind:\n",
    "                            if inverse_node_map[a2]==a and external_map_out[other_ind][0]==inverse_node_map[external_leg_out[ind][0]]:\n",
    "                                if (other_ind, ind) not in internal_mapping:\n",
    "                                    internal_mapping.add((other_ind, ind)) # arbitrary ordering \n",
    "                    for other_ind, (a2, b2) in external_leg_in.items():\n",
    "                        if other_ind is not ind:\n",
    "                            if inverse_node_map[a2]==a and external_map_in[other_ind][0]==inverse_node_map[external_leg_out[ind][0]]:\n",
    "                                if (other_ind, ind) not in internal_mapping:\n",
    "                                    internal_mapping.add((other_ind, ind)) # ordering ???         \n",
    "\n",
    "            for index in external_map_in2:\n",
    "                vs = self.TF.edge_space[G2.node[external_leg_replace_in[index][0]+shift]['content']][external_leg_replace_in[index][1]]\n",
    "                G3.add_edge(external_map_in2[index][0], external_leg_replace_in[index][0]+shift, start_pos=external_map_in2[index][1],\n",
    "                            end_pos=external_leg_replace_in[index][1], vector_space=vs)\n",
    "            for index in external_map_out2:\n",
    "                vs = self.TF.edge_space[G2.node[external_leg_replace_out[index][0]+shift]['content']][external_leg_replace_out[index][1]]\n",
    "                G3.add_edge(external_leg_replace_out[index][0]+shift, external_map_out2[index][0], end_pos=external_map_out2[index][1],\n",
    "                            start_pos=external_leg_replace_out[index][1], vector_space=vs)\n",
    "\n",
    "\n",
    "    #         print(internal_mapping)\n",
    "    #         print(external_leg_in)\n",
    "    #         print(external_leg_out)\n",
    "            for ind1, ind2 in internal_mapping:\n",
    "                if ind1 in external_leg_in:\n",
    "                    vs = self.TF.edge_space[G2.node[external_leg_replace_in[ind1][0]+shift]['content']][external_leg_replace_in[ind1][1]]       \n",
    "                    if ind2 in external_leg_in:\n",
    "                        G3.add_edge(external_leg_replace_in[ind1][0]+shift, external_leg_replace_in[ind2][0]+shift,\n",
    "                            start_pos=external_leg_replace_in[ind1][1],\n",
    "                            end_pos  =external_leg_replace_in[ind2][1], vector_space=vs)\n",
    "                    else:\n",
    "                        G3.add_edge(external_leg_replace_out[ind2][0]+shift, external_leg_replace_in[ind1][0]+shift,\n",
    "                            start_pos=external_leg_replace_out[ind2][1],\n",
    "                            end_pos  =external_leg_replace_in[ind1][1], vector_space=vs)\n",
    "                else:\n",
    "                    vs = self.TF.edge_space[G2.node[external_leg_replace_out[ind1][0]+shift]['content']][external_leg_replace_out[ind1][1]]\n",
    "                    if ind2 in external_leg_in:\n",
    "                        G3.add_edge(external_leg_replace_out[ind1][0]+shift, external_leg_replace_in[ind2][0]+shift,\n",
    "                            start_pos=external_leg_replace_out[ind1][1],\n",
    "                            end_pos  =external_leg_replace_in[ind2][1], vector_space=vs)\n",
    "                    else:\n",
    "                        G3.add_edge(external_leg_replace_out[ind1][0]+shift, external_leg_replace_out[ind2][0]+shift,\n",
    "                            start_pos=external_leg_replace_out[ind1][1],\n",
    "                            end_pos  =external_leg_replace_out[ind2][1], vector_space=vs)\n",
    "\n",
    "\n",
    "\n",
    "            relabel = {}\n",
    "            for n in G3.nodes:\n",
    "                if G3.nodes[n]['index']:\n",
    "                    relabel[n] = n+len(G3)\n",
    "                else:\n",
    "                    relabel[n] = n\n",
    "            G3 = nx.relabel_nodes(G3, relabel)\n",
    "            G3 = nx.relabel.convert_node_labels_to_integers(G3, first_label=0, ordering=\"sorted\")\n",
    "            \n",
    "            G3.graph['prefactor'] = pref\n",
    "            \n",
    "            resulting_tensor.append(tensor(self.TF, graph=G3))\n",
    "        \n",
    "        \n",
    "        if len(resulting_tensor)==1:\n",
    "            self.graph = resulting_tensor[0].graph\n",
    "            return True\n",
    "        else:\n",
    "            self.leaf = False\n",
    "            self.graph = nx.MultiDiGraph(prefactor=1, indices=[])\n",
    "            self.operator = add_var\n",
    "            self.prefactor = 1\n",
    "            self.operands = resulting_tensor\n",
    "            return True\n",
    "        \n",
    "    def simplify_step(self):\n",
    "        \"\"\"\n",
    "        Apply a single simplification step.\n",
    "        Return True if somthing was changed, False otherwise.\n",
    "        \"\"\"\n",
    "        if self.leaf:\n",
    "            if self.fully_simplified:\n",
    "                return False\n",
    "            if self.match_step():\n",
    "                return True\n",
    "            else:\n",
    "                self.fully_simplified = True\n",
    "                return False\n",
    "        \n",
    "        res = []\n",
    "        for op in self.operands:\n",
    "            if not op.fully_simplified:\n",
    "                if op.match_step():\n",
    "                    res.append(True)\n",
    "                else:\n",
    "                    op.fully_simplified = True\n",
    "                    res.append(False)\n",
    "            else:\n",
    "                res.append(False)\n",
    "                \n",
    "        self.expand()\n",
    "        self.remove_zero_contributions()\n",
    "        \n",
    "        if res.count(False)/len(res) > 0.9:\n",
    "            self.simplify_isom()\n",
    "        \n",
    "        return any(res)\n",
    "            \n",
    "    def simplify(self):\n",
    "        \"\"\"\n",
    "        Apply simplification steps for as long as needed.\n",
    "        \"\"\"\n",
    "        while self.simplify_step():\n",
    "            pass\n",
    "    \n",
    "    def remove_zero_contributions(self):\n",
    "        \"\"\"\n",
    "        Remove tensors equal to zero in a sum\n",
    "        \"\"\"\n",
    "        if self.operator is not add_var:\n",
    "            return\n",
    "        \n",
    "        n = len(self.operands)\n",
    "        for i, op in enumerate(reversed(self.operands)):\n",
    "            if SR(op.prefactor).is_trivial_zero():\n",
    "                del self.operands[n-i-1]\n",
    "        \n",
    "        \n",
    "#         self.operands = [op for op in self.operands if op.prefactor!=0]\n",
    "    \n",
    "    def __add__(self, other):\n",
    "        \"\"\"\n",
    "        Add 2 tensors. Should be improved\n",
    "        \"\"\"\n",
    "        if self.operator is not add_var and other.operator is not add_var:\n",
    "            res = tensor(self.TF, 1)\n",
    "            res.operator = add_var\n",
    "            res.operands = [self.__copy__(), other.__copy__()]\n",
    "            res.leaf = False\n",
    "            res.E = self.E+other.E\n",
    "            res.is_scalar = self.is_scalar and other.is_scalar   \n",
    "            res.prefactor = 1\n",
    "            return res\n",
    "\n",
    "        if self.operator is add_var and other.operator is not add_var:\n",
    "            res = self.__copy__()\n",
    "            res.operands.append(other.__copy__())\n",
    "            res.E += other.E\n",
    "            return res\n",
    "\n",
    "        if self.operator is not add_var and other.operator is add_var:\n",
    "            res = other.__copy__()\n",
    "            res.operands.append(self.__copy__())\n",
    "            res.E += self.E\n",
    "            return res\n",
    "\n",
    "        if self.operator is add_var and other.operator is add_var:\n",
    "            res = other.__copy__()\n",
    "            res.operands += self.__copy__().operands\n",
    "            res.E += self.E\n",
    "            return res\n",
    " \n",
    "    def __copy__(self):\n",
    "        \"\"\"\n",
    "        Shallow copy. \n",
    "        \"\"\"\n",
    "        res = tensor(self.TF, 1)\n",
    "        res.operator = self.operator\n",
    "        if res.operator is add_var:\n",
    "            res.operands = [op.__copy__() for op in self.operands]\n",
    "        else:\n",
    "            res.operands = copy(self.operands)\n",
    "        res.leaf = self.leaf\n",
    "        res.E = self.E\n",
    "        res.is_scalar = self.is_scalar \n",
    "        res.prefactor = self.prefactor\n",
    "        res.graph = self.graph.copy()\n",
    "        res.fully_simplified = self.fully_simplified\n",
    "        return res\n",
    "    \n",
    "    def __mul__(self, other):\n",
    "        \"\"\"\n",
    "        Multiply 2 tensors. Should be improved\n",
    "        \"\"\"\n",
    "        if self.operator is not add_var and other.operator is not add_var:\n",
    "            res = tensor(self.TF, 1)\n",
    "            res.operator = mul_var\n",
    "            res.operands = []\n",
    "            res.leaf = True\n",
    "            res.ext_ind = self.ext_ind+other.ext_ind\n",
    "            res. E = self.E*other.E\n",
    "            res.is_scalar = self.is_scalar and other.is_scalar\n",
    "            G = other.graph.copy()\n",
    "            rename = {}\n",
    "            for n in G.nodes:\n",
    "                rename[n] = n+len(self.graph)\n",
    "            nx.relabel_nodes(G, rename, copy=False)\n",
    "            res.graph = nx.union(self.graph, G)\n",
    "            res.normalize_graph()\n",
    "            res.graph.graph['prefactor'] = self.prefactor*other.prefactor\n",
    "            res.prefactor = self.prefactor*other.prefactor\n",
    "            res.graph.graph['indices'] = res.ext_ind\n",
    "            return res\n",
    "\n",
    "        if self.operator is add_var and other.operator is not add_var:\n",
    "            res = []\n",
    "            for op in self.operands:\n",
    "                res.append(op*other)\n",
    "            return sum(res[1:len(res)], res[0])\n",
    "\n",
    "        if self.operator is not add_var and other.operator is add_var:\n",
    "            return other.__mul__(self)\n",
    "\n",
    "        if self.operator is add_var and other.operator is add_var:\n",
    "            res = []\n",
    "            for op in self.operands:\n",
    "                for op2 in other.operands:\n",
    "                    res.append(op*op2)\n",
    "            return sum(res[1:len(res)], res[0])\n",
    "        \n",
    "    def simplify_isom(self):\n",
    "        \"\"\"\n",
    "        Look for isomorphisms between terms in a sum of tensors, to factorize de contributions.\n",
    "        This function can slow because if n is the number of non_isomorphic terms, it will perform\n",
    "        at least n(n-1)/2 isomorphism tests.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.operator is not add_var:\n",
    "            return\n",
    "\n",
    "        def test_edge(e1, e2):\n",
    "        #     print(e1, e2)\n",
    "            return bool(str(e1[0]['content'])==str(e2[0]['content']))\n",
    "\n",
    "        def test_node(n1, n2):\n",
    "        #     print(n1, n2)\n",
    "            return (n1['start_pos']==n2['start_pos'] and n1['end_pos']==n2['end_pos']) or \\\n",
    "                        (self.share_a_symmetry(n1['start_pos'], n2['start_pos'], n1['start_content']) and \n",
    "                         self.share_a_symmetry(n1['end_pos'], n2['end_pos'], n1['end_content'])) # ensures edges are of the same type\n",
    "\n",
    "        classes = {}\n",
    "        representant = {}\n",
    "        line_graphs = {}\n",
    "        for i in range(len(self.operands)):\n",
    "            G1 = self.operands[i].graph.copy()\n",
    "            G10 = self.operands[i].graph.copy()\n",
    "            ed = G1.edges\n",
    "            for e in list(ed):\n",
    "                G1.add_edge(e[1], e[0], start_pos=ed[e]['end_pos'], end_pos=ed[e]['start_pos'], vector_space=ed[e]['vector_space'])\n",
    "            for e in ed:\n",
    "                G1.edges[e]['start_content'] = G1.node[e[0]]['content']\n",
    "                G1.edges[e]['end_content'] = G1.node[e[1]]['content']\n",
    "            line_graphs[i] = self.line_graph(G1)\n",
    "            for j in representant:\n",
    "                G2 = representant[j]\n",
    "                accepted = False\n",
    "                if isomorphism.faster_could_be_isomorphic(line_graphs[i], line_graphs[j]): # 20% speedup\n",
    "                    GM = isomorphism.DiGraphMatcher(line_graphs[i], line_graphs[j], edge_match=test_edge, node_match=test_node)\n",
    "                    for mapping in GM.isomorphisms_iter():\n",
    "                        edge_map = mapping\n",
    "                        node_map = {}\n",
    "                        for a in edge_map:\n",
    "                            node_map[a[0]] = edge_map[a][0]\n",
    "                            node_map[a[1]] = edge_map[a][1]\n",
    "\n",
    "                        edge_map_2 = {}\n",
    "                        for e in edge_map:\n",
    "                            if e in G10.edges and all([G1.edges[e][a]==G10.edges[e][a] for a in G10.edges[e]]):\n",
    "                                edge_map_2[e] = edge_map[e]\n",
    "\n",
    "    #                     print(all([e in G2.edges for e in edge_map.values()]), all([e in G1.edges for e in edge_map.values()]))\n",
    "\n",
    "                        accept = True\n",
    "                        sign = []\n",
    "                        for n in node_map:\n",
    "                            perm = {}\n",
    "                            for e in edge_map_2:\n",
    "\n",
    "    #                             print(G10.edges[e])\n",
    "    #                             print(G2.edges[edge_map_2[e]])\n",
    "\n",
    "                                if n==e[0]:\n",
    "                                    perm[G10.edges[e]['start_pos']] = G2.edges[edge_map_2[e]]['start_pos']\n",
    "                                if n==e[1]:\n",
    "                                    perm[G10.edges[e]['end_pos']] = G2.edges[edge_map_2[e]]['end_pos']\n",
    "                            p2, s = self.TF.sign_permutation(perm, G1.nodes[n]['content'])\n",
    "                            sign += [s]\n",
    "\n",
    "                            if s==0:\n",
    "                                accept = False\n",
    "\n",
    "                        sign = product(sign)\n",
    "                        if accept:\n",
    "                            classes[j] += sign*G1.graph['prefactor']\n",
    "                            accepted = True\n",
    "                            break\n",
    "\n",
    "                    if accepted:\n",
    "                        break               \n",
    "\n",
    "            else:\n",
    "                classes[i] = G1.graph['prefactor']\n",
    "                representant[i] = G1\n",
    "                \n",
    "\n",
    "#         print(len(self.operands), len(classes))\n",
    "        for i in classes:\n",
    "            self.operands[i].prefactor = classes[i]\n",
    "            self.operands[i].graph.graph['prefactor'] = classes[i]\n",
    "\n",
    "        self.operands = [self.operands[i] for i in classes]\n",
    "\n",
    "        if len(self.operands)==1:\n",
    "            self.operator = mul_var\n",
    "            self.graph = self.operands[0].graph\n",
    "            self.prefactor = self.graph.graph['prefactor']\n",
    "            self.leaf = True\n",
    "            self.operands = [1]\n",
    "            \n",
    "    def to_expression(self):\n",
    "        \"\"\"\n",
    "        Convert graph to symbolic expression.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.operator is add_var and len(self.operands)>1:\n",
    "            return sum([op.to_expression() for op in self.operands])\n",
    "\n",
    "\n",
    "        def next_ind(i=-1, veto=[]):\n",
    "            i += 1\n",
    "            while(extended_greek_variables[i] in veto):\n",
    "                i += 1\n",
    "            return i\n",
    "        \n",
    "        indices = []\n",
    "        for n in self.graph.nodes:\n",
    "            if self.graph.nodes[n]['index']:\n",
    "                indices.append(self.graph.nodes[n]['content'])\n",
    "                \n",
    "        edge_map = {}\n",
    "        ind = next_ind(veto=indices)\n",
    "        for e in self.graph.edges:\n",
    "            if not self.graph.nodes[e[0]]['index'] and not self.graph.nodes[e[1]]['index']:\n",
    "                edge_map[e] = extended_greek_variables[ind]\n",
    "                ind = next_ind(ind, veto=indices)\n",
    "            elif self.graph.nodes[e[0]]['index']:\n",
    "                edge_map[e] = self.graph.nodes[e[0]]['content']\n",
    "            elif self.graph.nodes[e[1]]['index']:\n",
    "                edge_map[e] = self.graph.nodes[e[1]]['content']\n",
    "            else:\n",
    "                raise Exception(\"Two external indices are contracted with each other, this is not supposed to happen.\")     \n",
    "        res = self.graph.graph['prefactor']\n",
    "        \n",
    "        for n in self.graph.nodes: \n",
    "            if not self.graph.nodes[n]['index']:\n",
    "                current_indices = list(self.graph.out_edges(n, keys=True))+list(self.graph.in_edges(n, keys=True))\n",
    "                order = [self.graph.edges[e]['start_pos'] for e in self.graph.out_edges(n, keys=True)]+[self.graph.edges[e]['end_pos'] for e in self.graph.in_edges(n, keys=True)]\n",
    "                res *= self.graph.nodes[n]['content'](*[edge_map[current_indices[order.index(i)]] for i in range(len(order))])\n",
    "        return res\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preparser(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.0",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
